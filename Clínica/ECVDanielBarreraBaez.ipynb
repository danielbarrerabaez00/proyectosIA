{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo primero que hay que hacer es leer los datos del csv y guardarlos en una variable para trabajar con ellos.\n",
    "# Despues hay que seleccionar que valores queremos utilizar como target y cuales como data.\n",
    "# Una vez que los datos esten preparados \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['edad', 'creatinina_fosfocinasa', 'diabetes', 'sangre_contraccion',\n",
      "       'plaquetas', 'creatinina', 'sodio', 'seguimiento', 'fallecimiento',\n",
      "       'anemia', 'tension', 'sexo', 'fumador'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Importamos y mostramos el csv\n",
    "data = pd.read_csv('historial_clinico.csv',sep=',')\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            edad  creatinina_fosfocinasa  diabetes  \\\n",
      "edad                    1.000000               -0.082369 -0.101062   \n",
      "creatinina_fosfocinasa -0.082369                1.000000 -0.006182   \n",
      "diabetes               -0.101062               -0.006182  1.000000   \n",
      "sangre_contraccion      0.059874               -0.046627 -0.003191   \n",
      "plaquetas              -0.051613                0.032759  0.087311   \n",
      "creatinina              0.159779               -0.013695 -0.048982   \n",
      "sodio                  -0.045967                0.059351 -0.089418   \n",
      "seguimiento            -0.224914               -0.012341  0.035846   \n",
      "anemia                  0.087067               -0.196382 -0.009496   \n",
      "tension                 0.196697               -0.026612 -0.008618   \n",
      "sexo                   -0.065157               -0.077034  0.155967   \n",
      "fumador                 0.162492               -0.014739 -0.057832   \n",
      "\n",
      "                        sangre_contraccion  plaquetas  creatinina     sodio  \\\n",
      "edad                              0.059874  -0.051613    0.159779 -0.045967   \n",
      "creatinina_fosfocinasa           -0.046627   0.032759   -0.013695  0.059351   \n",
      "diabetes                         -0.003191   0.087311   -0.048982 -0.089418   \n",
      "sangre_contraccion                1.000000   0.076541   -0.009996  0.175839   \n",
      "plaquetas                         0.076541   1.000000   -0.045922  0.063085   \n",
      "creatinina                       -0.009996  -0.045922    1.000000 -0.189049   \n",
      "sodio                             0.175839   0.063085   -0.189049  1.000000   \n",
      "seguimiento                       0.040374   0.015331   -0.147934  0.087512   \n",
      "anemia                            0.029384  -0.036590    0.054925  0.041647   \n",
      "tension                          -0.114868   0.023593    0.148502 -0.065388   \n",
      "sexo                              0.150054   0.121192   -0.008643  0.027802   \n",
      "fumador                          -0.175789   0.039127    0.086016 -0.085576   \n",
      "\n",
      "                        seguimiento    anemia   tension      sexo   fumador  \n",
      "edad                      -0.224914  0.087067  0.196697 -0.065157  0.162492  \n",
      "creatinina_fosfocinasa    -0.012341 -0.196382 -0.026612 -0.077034 -0.014739  \n",
      "diabetes                   0.035846 -0.009496 -0.008618  0.155967 -0.057832  \n",
      "sangre_contraccion         0.040374  0.029384 -0.114868  0.150054 -0.175789  \n",
      "plaquetas                  0.015331 -0.036590  0.023593  0.121192  0.039127  \n",
      "creatinina                -0.147934  0.054925  0.148502 -0.008643  0.086016  \n",
      "sodio                      0.087512  0.041647 -0.065388  0.027802 -0.085576  \n",
      "seguimiento                1.000000 -0.144631 -0.410431  0.017415 -0.257917  \n",
      "anemia                    -0.144631  1.000000  0.064190  0.097908 -0.047247  \n",
      "tension                   -0.410431  0.064190  1.000000  0.090540  0.247032  \n",
      "sexo                       0.017415  0.097908  0.090540  1.000000 -0.282430  \n",
      "fumador                   -0.257917 -0.047247  0.247032 -0.282430  1.000000  \n"
     ]
    }
   ],
   "source": [
    "X = data[['edad','creatinina_fosfocinasa','diabetes','sangre_contraccion','plaquetas','creatinina','sodio','seguimiento','anemia','tension','sexo','fumador']].dropna()\n",
    "y = data['fallecimiento'].dropna()\n",
    "\n",
    "y = y.iloc[:-1]\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "print(X.corr())\n",
    "# Comprobamos si existe correlacion entre algunos datos para eliminarlos de ser asi.\n",
    "#Al no haber correlacion mantenemos los datos como estan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de LogisticRegression\n",
      "Score train: 0.8399664429530201\n",
      "Score test: 0.8399716704327005\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Fallecerá       0.85      0.92      0.89       101\n",
      "No fallecerá       0.80      0.67      0.73        48\n",
      "\n",
      "    accuracy                           0.84       149\n",
      "   macro avg       0.83      0.79      0.81       149\n",
      "weighted avg       0.84      0.84      0.83       149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo de clasificacion, en este caso usaremos el de LogisticRegression\n",
    "clf1 = LogisticRegression(C=1,class_weight=None,max_iter=100000)\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    # Stratify es muy importante porque hace que se cojan los datos en la proporcion que le pasemos en el train size\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,train_size=0.5,stratify=y)\n",
    "    clf1.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTest = np.append(scoreTrain,clf1.score(XTrain,yTrain))\n",
    "    scoreTrain = np.append(scoreTest,clf1.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de LogisticRegression')\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())\n",
    "\n",
    "labels=['Fallecerá','No fallecerá']\n",
    "cr = classification_report(yTest,clf1.predict(XTest),target_names=labels)\n",
    "print('\\n',cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de LinearDiscriminantAnalysis\n",
      "Score train: 0.8640939597315438\n",
      "Score test: 0.8641529796634178\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Fallecerá       0.85      0.95      0.90       101\n",
      "No fallecerá       0.86      0.65      0.74        48\n",
      "\n",
      "    accuracy                           0.85       149\n",
      "   macro avg       0.86      0.80      0.82       149\n",
      "weighted avg       0.85      0.85      0.85       149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo de clasificacion, en este caso usaremos el de LinearDiscriminantAnalysis\n",
    "clf2 =  LinearDiscriminantAnalysis()\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    # Stratify es muy importante porque hace que se cojan los datos en la proporcion que le pasemos en el train size\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,train_size=0.5,stratify=y)\n",
    "    clf2.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTest = np.append(scoreTrain,clf2.score(XTrain,yTrain))\n",
    "    scoreTrain = np.append(scoreTest,clf2.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de LinearDiscriminantAnalysis')\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())\n",
    "\n",
    "labels=['Fallecerá','No fallecerá']\n",
    "cr = classification_report(yTest,clf2.predict(XTest),target_names=labels)\n",
    "print('\\n',cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de QuadraticDiscriminantAnalysis\n",
      "Score train: 0.8408389261744966\n",
      "Score test: 0.8410171663687566\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Fallecerá       0.80      0.96      0.87       101\n",
      "No fallecerá       0.85      0.48      0.61        48\n",
      "\n",
      "    accuracy                           0.81       149\n",
      "   macro avg       0.82      0.72      0.74       149\n",
      "weighted avg       0.81      0.81      0.79       149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo de clasificacion, en este caso usaremos el de QuadraticDiscriminantAnalysis\n",
    "clf3 = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    # Stratify es muy importante porque hace que se cojan los datos en la proporcion que le pasemos en el train size\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,train_size=0.5,stratify=y)\n",
    "    clf3.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTest = np.append(scoreTrain,clf3.score(XTrain,yTrain))\n",
    "    scoreTrain = np.append(scoreTest,clf3.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de QuadraticDiscriminantAnalysis')\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())\n",
    "\n",
    "labels=['Fallecerá','No fallecerá']\n",
    "cr = classification_report(yTest,clf3.predict(XTest),target_names=labels)\n",
    "print('\\n',cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'degree': 2, 'gamma': 1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elegimos los parametros que queremos optimizar y sus posibles valores\n",
    "hiper={\n",
    "    'gamma':np.arange(1,11),\n",
    "    'C':np.arange(1,11),\n",
    "    'degree':[2,3,4,5]\n",
    "}\n",
    "\n",
    "#Elegimos que tipo de modelo vamos a entrenar\n",
    "clf3 = SVC()\n",
    "\n",
    "#Le pasamos al GridSearchCV el modelo, los hiperparametros y el cross validate\n",
    "gscv = GridSearchCV(clf3, hiper,cv=3)\n",
    "\n",
    "#Entrenamos el modelo\n",
    "gscv.fit(X,y)\n",
    "\n",
    "# Obtenemos los mejores parametros\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de SVC con los hiperparametros optimos calculados por el GridSearchCV\n",
      "Score train: 0.8365384615384616\n",
      "Score test: 0.8222222222222222\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Fallecerá       0.80      0.97      0.88        59\n",
      "No fallecerá       0.89      0.55      0.68        31\n",
      "\n",
      "    accuracy                           0.82        90\n",
      "   macro avg       0.85      0.76      0.78        90\n",
      "weighted avg       0.83      0.82      0.81        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# En este caso no lo he hecho con un bucle porque puede tardar bastante\n",
    "\n",
    "#Creamos el modelo de clasificacion SVC con los hiperparametros optimos calculados por el GridSearchCV\n",
    "clf4 = SVC(C=gscv.best_params_['C'],degree=gscv.best_params_['degree'], kernel='linear', gamma=gscv.best_params_['gamma'])\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,y,test_size=0.3)\n",
    "clf4.fit(XTrain,yTrain)\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos tanto para el test como para el train\n",
    "print('Resultados del modelo de SVC con los hiperparametros optimos calculados por el GridSearchCV')\n",
    "print('Score train:',clf4.score(XTrain,yTrain))\n",
    "print('Score test:',clf4.score(XTest,yTest))\n",
    "\n",
    "labels=['Fallecerá','No fallecerá']\n",
    "cr = classification_report(yTest,clf4.predict(XTest),target_names=labels)\n",
    "print('\\n',cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'min_samples_leaf': 8,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elegimos los parametros que queremos optimizar y sus posibles valores\n",
    "hiper={\n",
    "    'criterion':['gini','entropy','log_loss'],\n",
    "    'max_depth':[None,2,5,10],\n",
    "    'min_samples_split':[2,5,8,10],\n",
    "    'min_samples_leaf':[1,2,5,8,10]\n",
    "}\n",
    "\n",
    "#Elegimos que tipo de modelo vamos a entrenar\n",
    "clf5 = DecisionTreeClassifier()\n",
    "\n",
    "#Le pasamos al GridSearchCV el modelo, los hiperparametros y el cross validate\n",
    "gscv = GridSearchCV(clf5, hiper,cv=3)\n",
    "\n",
    "#Entrenamos el modelo\n",
    "gscv.fit(X,y)\n",
    "\n",
    "# Obtenemos los mejores parametros\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de DecisionTreeClassifier con los hiperparametros optimos calculados por el GridSearchCV\n",
      "Score train: 0.913173076923077\n",
      "Score test: 0.8562222222222223\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Fallecerá       0.86      0.88      0.87        68\n",
      "No fallecerá       0.60      0.55      0.57        22\n",
      "\n",
      "    accuracy                           0.80        90\n",
      "   macro avg       0.73      0.71      0.72        90\n",
      "weighted avg       0.79      0.80      0.80        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creamos el modelo de clasificacion DecisionTreeClassifier con los hiperparametros optimos calculados por el GridSearchCV\n",
    "clf5 = DecisionTreeClassifier(criterion=gscv.best_params_['criterion'],max_depth=gscv.best_params_['max_depth'],min_samples_split=gscv.best_params_['min_samples_split'],min_samples_leaf=gscv.best_params_['min_samples_leaf'],class_weight=None)\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,test_size=0.3)\n",
    "    clf5.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTrain = np.append(scoreTrain,clf5.score(XTrain,yTrain))\n",
    "    scoreTest = np.append(scoreTest,clf5.score(XTest,yTest))\n",
    "\n",
    "print('Resultados del modelo de DecisionTreeClassifier con los hiperparametros optimos calculados por el GridSearchCV')\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())\n",
    "\n",
    "labels=['Fallecerá','No fallecerá']\n",
    "cr = classification_report(yTest,clf5.predict(XTest),target_names=labels)\n",
    "print('\\n',cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
