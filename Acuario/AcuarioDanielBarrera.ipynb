{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo primero que hay que hacer es leer los datos del csv y guardarlos en una variable para trabajar con ellos.\n",
    "# Despues hay que seleccionar que valores queremos utilizar como target y cuales como data.\n",
    "# Una vez que los datos esten preparados \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR, NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Especie  Long_vert  Long_diag  Long_tras    Altura     Ancho\n",
      "Especie    1.000000  -0.217416  -0.230993  -0.262653 -0.483024 -0.391596\n",
      "Long_vert -0.217416   1.000000   0.999517   0.992031  0.625378  0.867050\n",
      "Long_diag -0.230993   0.999517   1.000000   0.994103  0.640441  0.873547\n",
      "Long_tras -0.262653   0.992031   0.994103   1.000000  0.703409  0.878520\n",
      "Altura    -0.483024   0.625378   0.640441   0.703409  1.000000  0.792881\n",
      "Ancho     -0.391596   0.867050   0.873547   0.878520  0.792881  1.000000\n"
     ]
    }
   ],
   "source": [
    "peces = pd.read_csv('acuario.csv',sep=',')\n",
    "\n",
    "X = peces[['Especie','Long_vert','Long_diag','Long_tras','Altura','Ancho']]\n",
    "y = peces['Peso']\n",
    "\n",
    "print(X.corr())\n",
    "\n",
    "X = peces[['Especie','Long_vert','Altura','Ancho']]\n",
    "# He quitado las longitudes transversales y diagonales porque estan correlacionadas a\n",
    "# mas del 99% con la longitud vertical. Esto significa que dichos datos no son necesarios\n",
    "# y eliminarlos mejoraria el rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESION LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de regresion lineal\n",
      "Score train: 0.8780293870650836\n",
      "Score test: 0.8783335058846512\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo de regresion. En este caso el lineal\n",
    "modelo1 = linear_model.LinearRegression()\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    # Stratify es muy importante porque hace que se cojan los datos en la proporcion que le pasemos en el train size:\n",
    "        # El 50% de los peces de tipo 0, el 50% de los peces de tipo 1...\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,stratify=X['Especie'], train_size=0.5)\n",
    "    modelo1.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTest = np.append(scoreTrain,modelo1.score(XTrain,yTrain))\n",
    "    scoreTrain = np.append(scoreTest,modelo1.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de regresion lineal')\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESION POLINOMICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de regresion polinomica de grado 2\n",
      "Score train: 0.9757281755600605\n",
      "Score test: 0.9758690279024493 \n",
      "\n",
      "Resultados del modelo de regresion polinomica de grado 3\n",
      "Score train: 0.8468751009359019\n",
      "Score test: 0.8464017249103306 \n",
      "\n",
      "Resultados del modelo de regresion polinomica de grado 4\n",
      "Score train: -57.48092404118788\n",
      "Score test: -57.77290850109615 \n",
      "\n",
      "Resultados del modelo de regresion polinomica de grado 5\n",
      "Score train: -59867.755649411774\n",
      "Score test: -59672.151107542144 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grado = [2,3,4,5]\n",
    "\n",
    "for i in grado:\n",
    "    modelo2 = linear_model.LinearRegression()\n",
    "    pf = PolynomialFeatures(degree=i)\n",
    "\n",
    "    # Crear dos lista numpy vacias\n",
    "    scoreTrain=np.array([])\n",
    "    scoreTest=np.array([])\n",
    "\n",
    "    XPol = pf.fit_transform(X)\n",
    "\n",
    "    # Creamos un bucle de 100 iteraciones\n",
    "    for j in range(0,100):\n",
    "\n",
    "        # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "        XTrainPol, XTestPol, yTrain, yTest = train_test_split(XPol,y,stratify=X['Especie'],train_size=0.6)\n",
    "        modelo2.fit(XTrainPol,yTrain)\n",
    "\n",
    "        # Agregamos el score del train y test a sus respectivas listas\n",
    "        scoreTest = np.append(scoreTrain,modelo2.score(XTrainPol,yTrain))\n",
    "        scoreTrain = np.append(scoreTest,modelo2.score(XTestPol,yTest))\n",
    "\n",
    "    # Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "    print('Resultados del modelo de regresion polinomica de grado',i)\n",
    "    print('Score train:',scoreTrain.mean())\n",
    "    print('Score test:',scoreTest.mean(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queda claro viendo los valores obtenidos que el mejor grado para la regresion polinomica es el grado 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO SVR LINEAR (sin usar gridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de SVR con kernel linear\n",
      "Score train: 0.8705250289143666\n",
      "Score test: 0.8528555411553124\n"
     ]
    }
   ],
   "source": [
    "#Introducimos los parametros para la creacion del modelo a mano.\n",
    "modelo3 = SVR(C=1.0, epsilon=1, kernel='linear')\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,stratify=X['Especie'],test_size=0.3)\n",
    "    modelo3.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTrain = np.append(scoreTrain,modelo3.score(XTrain,yTrain))\n",
    "    scoreTest = np.append(scoreTest,modelo3.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de SVR con kernel linear')\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO SVR LINEAR (usando gridSearchCV).\n",
    "GridSearchCV se encarga de elegir cuales son los mejores parametros posibles de todos los que le pases para el modelo que vas a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 9, 'epsilon': 37}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elegimos los parametros que queremos optimizar y sus posibles valores\n",
    "hiper={\n",
    "    'epsilon':np.arange(1,101),\n",
    "    'C':np.arange(1,10)\n",
    "}\n",
    "\n",
    "#Elegimos que tipo de modelo vamos a entrenar\n",
    "modelo3 = SVR()\n",
    "\n",
    "#Le pasamos al GridSearchCV el modelo, los hiperparametros y el cross validate\n",
    "gscv = GridSearchCV(modelo3, hiper, cv=3)\n",
    "\n",
    "#Entrenamos el modelo\n",
    "gscv.fit(X,y)\n",
    "\n",
    "# Obtenemos los mejores parametros\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de SVR con kernel linear usando los datos obtenidos por gridSearchCV\n",
      "Score train: 0.876468670572781\n",
      "Score test: 0.8576515461693752\n"
     ]
    }
   ],
   "source": [
    "#Creamos el modelo con los hiperparametros optimos calculados por el GridSearchCV\n",
    "modelo3 = SVR(C=gscv.best_params_['C'], epsilon=gscv.best_params_['epsilon'], kernel='linear')\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,stratify=X['Especie'],test_size=0.3)\n",
    "    modelo3.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTrain = np.append(scoreTrain,modelo3.score(XTrain,yTrain))\n",
    "    scoreTest = np.append(scoreTest,modelo3.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de SVR con kernel linear usando los datos obtenidos por gridSearchCV')\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al usar gridSearchCV podemos comprobar que los scores mejoran (en este caso ligeramente, pero mejoran) asi que a partir de ahora lo usaremos a la hora de entrenar todos los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO SVR POLY (usando gridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'degree': 1, 'epsilon': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elegimos los parametros que queremos optimizar y sus posibles valores\n",
    "hiper={\n",
    "    'epsilon':np.arange(1,11),\n",
    "    'C':np.arange(1,11),\n",
    "    'degree':np.arange(1,5)\n",
    "}\n",
    "\n",
    "#Elegimos que tipo de modelo vamos a entrenar\n",
    "modelo4 = SVR()\n",
    "\n",
    "#Le pasamos al GridSearchCV el modelo, los hiperparametros y el cross validate\n",
    "gscv = GridSearchCV(modelo4, hiper, cv=3)\n",
    "\n",
    "#Entrenamos el modelo\n",
    "gscv.fit(X,y)\n",
    "\n",
    "# Obtenemos los mejores parametros\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de SVR con kernel poly de grado 1\n",
      "Score train: 0.5683176277120243\n",
      "Score test: 0.5633611296196762\n"
     ]
    }
   ],
   "source": [
    "#Creamos el modelo con los hiperparametros optimos calculados por el GridSearchCV\n",
    "modelo4 = SVR(C=gscv.best_params_['C'], epsilon=gscv.best_params_['epsilon'], kernel='poly', degree=gscv.best_params_['degree'])\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,stratify=X['Especie'],test_size=0.3)\n",
    "    modelo4.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTrain = np.append(scoreTrain,modelo4.score(XTrain,yTrain))\n",
    "    scoreTest = np.append(scoreTest,modelo4.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de SVR con kernel poly de grado',gscv.best_params_['degree'])\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO SVR RBF (usando gridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 99, 'epsilon': 1, 'gamma': 'scale'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elegimos los parametros que queremos optimizar y sus posibles valores\n",
    "hiper={\n",
    "    'epsilon':np.arange(1,11),\n",
    "    'C':np.arange(1,100),\n",
    "    'gamma':['scale','auto']\n",
    "}\n",
    "\n",
    "#Elegimos que tipo de modelo vamos a entrenar\n",
    "modelo5 = SVR()\n",
    "\n",
    "#Le pasamos al GridSearchCV el modelo, los hiperparametros y el cross validate\n",
    "gscv = GridSearchCV(modelo5, hiper, cv=3)\n",
    "\n",
    "#Entrenamos el modelo\n",
    "gscv.fit(X,y)\n",
    "\n",
    "# Obtenemos los mejores parametros\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de SVR con kernel RBF\n",
      "Score train: 0.8837899676181952\n",
      "Score test: 0.8761319727626092\n"
     ]
    }
   ],
   "source": [
    "#Creamos el modelo con los hiperparametros optimos calculados por el GridSearchCV\n",
    "modelo5 = SVR(C=gscv.best_params_['C'], epsilon=gscv.best_params_['epsilon'], kernel='rbf', gamma=gscv.best_params_['gamma'])\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,stratify=X['Especie'],test_size=0.3)\n",
    "    modelo5.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTrain = np.append(scoreTrain,modelo5.score(XTrain,yTrain))\n",
    "    scoreTest = np.append(scoreTest,modelo5.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de SVR con kernel RBF')\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO SVR SIGMOID (usando gridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 99, 'epsilon': 1, 'gamma': 'scale'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elegimos los parametros que queremos optimizar y sus posibles valores\n",
    "hiper={\n",
    "    'epsilon':np.arange(1,11),\n",
    "    'C':np.arange(1,100),\n",
    "    'gamma':['scale','auto']\n",
    "}\n",
    "\n",
    "#Elegimos que tipo de modelo vamos a entrenar\n",
    "modelo6 = SVR()\n",
    "\n",
    "#Le pasamos al GridSearchCV el modelo, los hiperparametros y el cross validate\n",
    "gscv = GridSearchCV(modelo6, hiper, cv=3)\n",
    "\n",
    "#Entrenamos el modelo\n",
    "gscv.fit(X,y)\n",
    "\n",
    "# Obtenemos los mejores parametros\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de SVR con kernel sigmoid\n",
      "Score train: -3.0542435384035387\n",
      "Score test: -3.1825941340891326\n"
     ]
    }
   ],
   "source": [
    "#Creamos el modelo con los hiperparametros optimos calculados por el GridSearchCV\n",
    "modelo6 = SVR(C=gscv.best_params_['C'], epsilon=gscv.best_params_['epsilon'], kernel='sigmoid', gamma=gscv.best_params_['gamma'])\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,stratify=X['Especie'],test_size=0.3)\n",
    "    modelo6.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTrain = np.append(scoreTrain,modelo6.score(XTrain,yTrain))\n",
    "    scoreTest = np.append(scoreTest,modelo6.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de SVR con kernel sigmoid')\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO NUSVR RBF (usando gridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie.LAPTOP-CLQ1QH4Q\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "2376 fits failed out of a total of 14256.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2376 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\danie.LAPTOP-CLQ1QH4Q\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\danie.LAPTOP-CLQ1QH4Q\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\danie.LAPTOP-CLQ1QH4Q\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\danie.LAPTOP-CLQ1QH4Q\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'nu' parameter of NuSVR must be a float in the range (0.0, 1.0]. Got 5 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\danie.LAPTOP-CLQ1QH4Q\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [-5.11114419 -4.30102084 -1.50875897 ... -0.35398223 -0.33117861\n",
      "         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 99, 'degree': 1, 'gamma': 'scale', 'nu': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elegimos los parametros que queremos optimizar y sus posibles valores\n",
    "hiper={\n",
    "    'C':np.arange(1,100),\n",
    "    'nu':[0.01,0.05,0.1,0.5,1,5],\n",
    "    'gamma':['scale','auto'],\n",
    "    'degree':np.arange(1,5)\n",
    "}\n",
    "\n",
    "#Elegimos que tipo de modelo vamos a entrenar\n",
    "modelo7 = NuSVR()\n",
    "\n",
    "#Le pasamos al GridSearchCV el modelo, los hiperparametros y el cross validate\n",
    "gscv = GridSearchCV(modelo7, hiper, cv=3)\n",
    "\n",
    "#Entrenamos el modelo\n",
    "gscv.fit(X,y)\n",
    "\n",
    "# Obtenemos los mejores parametros\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo de NuSVR con kernel RBF de grado 1\n",
      "Score train: 0.8831536645996588\n",
      "Score test: 0.8703164362460319\n"
     ]
    }
   ],
   "source": [
    "#Creamos el modelo con los hiperparametros optimos calculados por el GridSearchCV\n",
    "modelo7 = NuSVR(C=gscv.best_params_['C'], kernel='rbf', gamma=gscv.best_params_['gamma'], nu=gscv.best_params_['nu'], degree=gscv.best_params_['degree'])\n",
    "\n",
    "# Crear dos lista numpy vacias\n",
    "scoreTrain=np.array([])\n",
    "scoreTest=np.array([])\n",
    "\n",
    "# Creamos un bucle de 100 iteraciones\n",
    "for i in range(0,100):\n",
    "\n",
    "    # En cada iteracion hacemos una division de los datos y entrenamos el modelos con esos valores\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(X,y,stratify=X['Especie'],test_size=0.3)\n",
    "    modelo7.fit(XTrain,yTrain)\n",
    "\n",
    "    # Agregamos el score del train y test a sus respectivas listas\n",
    "    scoreTrain = np.append(scoreTrain,modelo7.score(XTrain,yTrain))\n",
    "    scoreTest = np.append(scoreTest,modelo7.score(XTest,yTest))\n",
    "\n",
    "# Mostramos las medias de los scores obtenidos en las 100 iteraciones tanto para el test como para el train\n",
    "print('Resultados del modelo de NuSVR con kernel RBF de grado',gscv.best_params_['degree'])\n",
    "print('Score train:',scoreTrain.mean())\n",
    "print('Score test:',scoreTest.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
